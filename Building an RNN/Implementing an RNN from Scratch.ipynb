{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open(\"kafka.txt\",'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data consists of vocalbulary having 81 unique chars, and dataset having 137628 chars\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(\"Data consists of vocalbulary having {} unique chars, and dataset having {} chars\".format(vocab_size,data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert integers to characters and vice versa which would be referenced further ahead.\n",
    "char_to_ints = {ch:i for i,ch in enumerate(chars)}\n",
    "ints_to_char = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 0, 'J': 1, 'v': 2, ' ': 3, 'O': 4, 'x': 5, 'A': 6, 'n': 7, 'l': 8, '(': 9, 'g': 10, 't': 11, ';': 12, 'p': 13, 'o': 14, 'z': 15, 'Q': 16, 'W': 17, 'H': 18, 'C': 19, 'm': 20, 'L': 21, 'i': 22, ':': 23, 'K': 24, 'S': 25, 'w': 26, \"'\": 27, 'R': 28, '9': 29, '3': 30, 'f': 31, 'e': 32, 'X': 33, '/': 34, '@': 35, '2': 36, 'T': 37, '8': 38, ',': 39, '0': 40, 'q': 41, 'I': 42, 'U': 43, 'k': 44, '\\n': 45, '*': 46, '7': 47, '%': 48, '\"': 49, 'y': 50, ')': 51, '5': 52, '!': 53, '§': 54, 'c': 55, 'Ã': 56, 'd': 57, '$': 58, '.': 59, 'D': 60, 'N': 61, '6': 62, 'b': 63, 'r': 64, 'h': 65, 'P': 66, 'V': 67, '4': 68, 'G': 69, 'u': 70, 'F': 71, '1': 72, 's': 73, '?': 74, 'a': 75, 'B': 76, 'E': 77, 'Y': 78, '-': 79, 'j': 80}\n",
      "{0: 'M', 1: 'J', 2: 'v', 3: ' ', 4: 'O', 5: 'x', 6: 'A', 7: 'n', 8: 'l', 9: '(', 10: 'g', 11: 't', 12: ';', 13: 'p', 14: 'o', 15: 'z', 16: 'Q', 17: 'W', 18: 'H', 19: 'C', 20: 'm', 21: 'L', 22: 'i', 23: ':', 24: 'K', 25: 'S', 26: 'w', 27: \"'\", 28: 'R', 29: '9', 30: '3', 31: 'f', 32: 'e', 33: 'X', 34: '/', 35: '@', 36: '2', 37: 'T', 38: '8', 39: ',', 40: '0', 41: 'q', 42: 'I', 43: 'U', 44: 'k', 45: '\\n', 46: '*', 47: '7', 48: '%', 49: '\"', 50: 'y', 51: ')', 52: '5', 53: '!', 54: '§', 55: 'c', 56: 'Ã', 57: 'd', 58: '$', 59: '.', 60: 'D', 61: 'N', 62: '6', 63: 'b', 64: 'r', 65: 'h', 66: 'P', 67: 'V', 68: '4', 69: 'G', 70: 'u', 71: 'F', 72: '1', 73: 's', 74: '?', 75: 'a', 76: 'B', 77: 'E', 78: 'Y', 79: '-', 80: 'j'}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_ints)\n",
    "print(ints_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# vector for char a\n",
    "\n",
    "vector_for_a = np.zeros((vocab_size,1))\n",
    "vector_for_a[char_to_ints['a']]=1\n",
    "print(vector_for_a.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "# hyperparameter\n",
    "\n",
    "hidden_size = 100\n",
    "seq_length = 25\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters \n",
    "\n",
    "# input to hidden stage weight\n",
    "Wxh = np.random.randn(hidden_size,vocab_size)*0.01\n",
    "\n",
    "# Recurrent weight matrix, hidden to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01 \n",
    "\n",
    "# hidden state to output value\n",
    "Why = np.random.randn(vocab_size, hidden_size) * 0.01 \n",
    "\n",
    "# bias to hidden\n",
    "bh = np.zeros((hidden_size, 1))\n",
    "\n",
    "# bias to output\n",
    "by = np.zeros((vocab_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(inputs,targets,hprev):\n",
    "    \n",
    "    # xs = one hot encoded characters\n",
    "    # hs = hidden state outputs\n",
    "    # ys = target values \n",
    "    # ps = probability of the outcomes for normalized probabilites for chars\n",
    "    \n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    \n",
    "    # initialize with the previous hidden states\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    \n",
    "    # initialize loss as 0\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    # forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        \n",
    "        # encode in 1-of-k representation (we place a 0 vector as the t-th input)                                   \n",
    "        xs[t] =  np.zeros((vocab_size,1))    \n",
    "        \n",
    "        # Inside that t-th input we use the integer in \"inputs\" list to  set the correct\n",
    "        xs[t][inputs[t]] = 1\n",
    "        \n",
    "        # hidden state\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) \n",
    "        \n",
    "        # unnormalized log probabilities for next chars                                                                                                           \n",
    "        ys[t] = np.dot(Why, hs[t]) + by \n",
    "        \n",
    "        # probabilities for next chars \n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))                                                                                                              \n",
    "        \n",
    "        # softmax (cross-entropy loss)  \n",
    "        loss += -np.log(ps[t][targets[t],0])        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
